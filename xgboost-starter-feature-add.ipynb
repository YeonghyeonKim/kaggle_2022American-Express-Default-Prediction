{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# XGBoost Starter - LB 0.793\nIn this notebook we build and train an XGBoost model using @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. This XGB model achieves CV 0.792 LB 0.793! When training with XGB, we use a special XGB dataloader called `DeviceQuantileDMatrix` which uses a small GPU memory footprint. This allows us to engineer more additional columns and train with more rows of data. Our feature engineering is performed using [RAPIDS][5] on the GPU to create new features quickly.\n\n[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n[5]: https://rapids.ai/","metadata":{}},{"cell_type":"markdown","source":"Feature Engineering I done\n1. Drop B_29, https://www.kaggle.com/code/roberthatch/amex-feature-engg-gpu-or-cpu-process-in-chunks/notebook\n2. Add each customer count (how long they used) (not normalize)\n3. Don't fill NaN (with -127)\n4. remove num_features's min, std\n5. D_39에 대한 feature 추가 -> CV하락\n6. B_1과 B_2간의 연관 feature 추가; CV 0.7920\n7. B_8과 B_9간의 연관 feature 추가; CV 0.7919\n8. corr가 높은 feature중 제거; CV: 0.7914\n9. 6+ fillna(method='bfill'); CV: 0.7906 => NaN으로 냅두자\n10. 마지막 3개월만 이용; 6 + CV: 0.7892; 4 + CV: 0.7886\n11. 영향도 낮은 features  제거 R_28, D_94, R_2; 10 + CV: 0.7890,4 + CV: 0.7916, 6 + CV: 0.7921\n12. Test시 Fold4 제외; LB에서 체크 예정\n13. 영향도가 0인 features 제거; 12 + CV: 0.7921 (LB 등록시 12번을 적용할지 말지 선택해야함)  \n13-2. 영향도 범위를 조금 늘림ㅣ 12 + CV: 0.7923, LB: 0.790\n<!-- 9. add nasdaq info simply -->","metadata":{}},{"cell_type":"markdown","source":"# Load Libraries","metadata":{}},{"cell_type":"code","source":"# LOAD LIBRARIES\nimport pandas as pd, numpy as np # CPU libraries\nimport cupy, cudf # GPU libraries\nimport matplotlib.pyplot as plt, gc, os\n\nprint('RAPIDS version',cudf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:52:45.787160Z","iopub.execute_input":"2022-07-30T17:52:45.787816Z","iopub.status.idle":"2022-07-30T17:52:45.795512Z","shell.execute_reply.started":"2022-07-30T17:52:45.787771Z","shell.execute_reply":"2022-07-30T17:52:45.794752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VERSION NAME FOR SAVED MODEL FILES\nVER = 1\n\n# TRAIN RANDOM SEED\nSEED = 42\n\n# FILL NAN VALUE\nNAN_VALUE = -127 # will fit in int8\n\n# FOLDS PER MODEL\nFOLDS = 5","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:52:45.936082Z","iopub.execute_input":"2022-07-30T17:52:45.936486Z","iopub.status.idle":"2022-07-30T17:52:45.941549Z","shell.execute_reply.started":"2022-07-30T17:52:45.936452Z","shell.execute_reply":"2022-07-30T17:52:45.940633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process and Feature Engineer Train Data\nWe will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n\n[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n[5]: https://rapids.ai/","metadata":{}},{"cell_type":"code","source":"def read_file(path = '', usecols = None):\n    # LOAD DATAFRAME\n    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n    else: df = cudf.read_parquet(path)\n    # REDUCE DTYPE FOR CUSTOMER AND DATE\n    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n    df.S_2 = cudf.to_datetime( df.S_2 )\n    # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n    #df = df.sort_values(['customer_ID','S_2'])\n    #df = df.reset_index(drop=True)\n    # FILL NAN\n#     df = df.fillna(NAN_VALUE) \n    print('shape of data:', df.shape)\n    \n    return df\n\nprint('Reading train data...')\nTRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\ntrain = read_file(path = TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:57:14.337706Z","iopub.execute_input":"2022-07-30T17:57:14.338259Z","iopub.status.idle":"2022-07-30T17:57:16.094944Z","shell.execute_reply.started":"2022-07-30T17:57:14.338217Z","shell.execute_reply":"2022-07-30T17:57:16.092525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:57:16.097641Z","iopub.status.idle":"2022-07-30T17:57:16.099734Z","shell.execute_reply.started":"2022-07-30T17:57:16.099485Z","shell.execute_reply":"2022-07-30T17:57:16.099519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_and_feature_engineer(df):\n    # FEATURE ENGINEERING FROM \n    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n#     9) nasdaq\n#     nasdaq_path = '../input/nasdaq/nasdaq.csv'\n#     nasdaq = cudf.read_csv(nasdaq_path, encoding='utf-8-sig')\n#     nasdaq.rename(columns={'\\ufeffS_2': 'S_2'}, inplace=True)\n#     nasdaq.drop(['tradingvolume'], inplace=True, axis=1)\n#     nasdaq.S_2 = cudf.to_datetime(nasdaq.S_2)\n#     nasdaq[['closing','open', 'high', 'low']] = nasdaq[['closing','open', 'high', 'low']].astype(float)    \n#     df = df.merge(nasdaq, on='S_2')\n    \n#     1) Drop 'B_29'\n    df.drop(['B_29'], inplace=True, axis=1)\n#     11) Drop R_28, D_94, R_2\n    df.drop(['R_28', 'D_94', 'R_2'], inplace=True, axis=1)\n    \n#     6) B1, B2에 연관 feature추가\n    df['B_1_2'] = df['B_1']/(df['B_2']+0.0000001)\n\n#     5) D_39에 대한 feature 추가\n#     df['D_39_div30'] = df['D_39']/30\n#     10) 마지막 3개월만 이용\n#     df = cudf.concat([df.groupby('customer_ID').nth(-3), df.groupby('customer_ID').nth(-2), df.groupby('customer_ID').nth(-1)]).reset_index()\n\n    \n    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n    num_features = [col for col in all_cols if col not in cat_features]\n    \n#     2) Add customer count\n    test_count_agg = df.groupby(['customer_ID'])['S_2'].agg(['count'])\n\n\n    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'max', 'last'])\n    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n\n    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n\n    df = cudf.concat([test_count_agg,test_num_agg, test_cat_agg], axis=1)\n#     13) \n    df.drop(['D_119_last',\n 'D_79_last',\n 'B_39_mean',\n 'B_15_max',\n 'B_32_mean',\n 'D_41_mean',\n 'D_141_max',\n 'R_27_mean',\n 'S_9_mean',\n 'D_70_last',\n 'B_19_mean',\n 'D_131_max',\n 'D_138_last',\n 'D_111_mean',\n 'D_134_last',\n 'D_74_max',\n 'R_15_mean',\n 'D_39_mean',\n 'S_11_max',\n 'R_7_mean',\n 'R_9_max',\n 'R_26_last',\n 'B_17_mean',\n 'D_131_last',\n 'B_30_last',\n 'B_26_last',\n 'B_33_last',\n 'D_61_mean',\n 'D_125_mean',\n 'B_38_nunique',\n 'S_27_last',\n 'B_36_mean',\n 'D_144_last',\n 'D_84_last',\n 'B_26_mean',\n 'S_25_mean',\n 'B_4_mean',\n 'R_6_mean',\n 'B_42_max',\n 'S_6_last',\n 'D_105_mean',\n 'D_133_mean',\n 'R_14_max',\n 'B_18_max',\n 'P_3_mean',\n 'D_126_nunique',\n 'B_19_last',\n 'D_96_last',\n 'S_13_mean',\n 'S_19_mean',\n 'R_4_last',\n 'D_143_mean',\n 'S_15_last',\n 'D_145_mean',\n 'D_86_last',\n 'D_63_last',\n 'D_54_last',\n 'D_106_max',\n 'D_104_last',\n 'B_39_last',\n 'D_69_last',\n 'P_3_last',\n 'D_83_max',\n 'R_7_max',\n 'B_21_last',\n 'B_19_max',\n 'B_41_mean',\n 'R_26_max',\n 'S_7_max',\n 'D_102_mean',\n 'S_25_last',\n 'D_78_mean',\n 'R_16_last',\n 'B_24_max',\n 'D_104_max',\n 'R_12_last',\n 'D_69_max',\n 'D_141_last',\n 'S_18_mean',\n 'D_142_last',\n 'R_6_last',\n 'B_13_mean',\n 'B_13_last',\n 'S_19_max',\n 'D_142_max',\n 'B_8_mean',\n 'D_144_mean',\n 'S_12_max',\n 'B_27_last',\n 'D_129_last',\n 'D_106_mean',\n 'D_86_mean',\n 'D_48_mean',\n 'B_24_last',\n 'B_27_max',\n 'D_93_last',\n 'S_24_mean',\n 'B_36_last',\n 'D_58_mean',\n 'D_141_mean',\n 'R_27_max',\n 'S_17_max',\n 'D_144_max',\n 'D_124_max',\n 'R_20_last',\n 'S_26_last',\n 'D_72_max',\n 'D_130_last',\n 'D_125_max',\n 'D_114_nunique',\n 'R_11_max',\n 'D_44_mean',\n 'S_17_mean',\n 'D_65_last',\n 'D_92_last',\n 'R_8_mean',\n 'D_136_mean',\n 'D_124_mean',\n 'D_132_last',\n 'D_79_max',\n 'D_78_max',\n 'B_30_count',\n 'D_66_nunique',\n 'D_74_last',\n 'D_91_max',\n 'S_16_last',\n 'D_86_max',\n 'D_110_mean',\n 'B_32_last',\n 'D_82_last',\n 'B_39_max',\n 'R_22_mean',\n 'D_142_mean',\n 'D_124_last',\n 'D_128_mean',\n 'D_131_mean',\n 'D_78_last',\n 'P_4_last',\n 'D_73_max',\n 'D_110_last',\n 'S_16_max',\n 'R_15_last',\n 'D_84_mean',\n 'D_145_max',\n 'B_24_mean',\n 'R_15_max',\n 'S_19_last',\n 'D_82_max',\n 'D_135_mean',\n 'D_50_mean',\n 'S_13_max',\n 'R_16_max',\n 'R_21_mean',\n 'D_72_last',\n 'B_6_mean',\n 'D_111_max',\n 'D_137_mean',\n 'S_13_last',\n 'D_107_max',\n 'D_132_mean',\n 'D_138_max',\n 'D_130_max',\n 'D_107_last',\n 'D_54_max',\n 'S_6_mean',\n 'R_14_mean',\n 'D_88_last',\n 'D_109_mean',\n 'R_20_mean',\n 'D_53_mean',\n 'D_89_mean',\n 'D_130_mean',\n 'S_20_mean',\n 'D_107_mean',\n 'R_24_last',\n 'D_139_mean',\n 'D_105_last',\n 'R_5_mean',\n 'D_138_mean',\n 'D_117_nunique',\n 'B_27_mean',\n 'D_73_mean',\n 'D_104_mean',\n 'D_115_max',\n 'D_136_max',\n 'B_36_max',\n 'B_10_max',\n 'D_126_last',\n 'D_96_mean',\n 'R_12_max',\n 'D_82_mean',\n 'R_24_mean',\n 'R_4_mean',\n 'R_25_mean',\n 'D_145_last',\n 'D_116_nunique',\n 'S_17_last',\n 'D_63_nunique',\n 'D_68_nunique',\n 'R_16_mean',\n 'D_108_max',\n 'B_26_max',\n 'D_73_last',\n 'B_38_last',\n 'R_9_last',\n 'D_108_mean',\n 'D_135_last',\n 'D_89_last',\n 'D_125_last',\n 'R_10_last',\n 'D_59_last',\n 'D_80_mean',\n 'S_12_last',\n 'R_14_last',\n 'D_79_mean',\n 'D_64_nunique',\n 'R_23_mean',\n 'D_81_mean',\n 'D_118_mean',\n 'D_84_max',\n 'D_68_last',\n 'D_136_last',\n 'D_116_last',\n 'R_10_max',\n 'B_31_last',\n 'D_75_last',\n 'R_5_max',\n 'D_80_max',\n 'D_134_mean',\n 'R_25_last',\n 'B_41_max',\n 'D_103_mean',\n 'R_13_mean',\n 'D_52_mean',\n 'R_20_max',\n 'R_13_max',\n 'B_41_last',\n 'D_81_max',\n 'S_20_last',\n 'R_12_mean',\n 'D_127_max',\n 'B_6_max',\n 'D_54_mean',\n 'B_31_mean',\n 'D_135_max',\n 'R_17_mean',\n 'S_18_last',\n 'R_22_last',\n 'D_114_count',\n 'B_22_max',\n 'D_139_last',\n 'D_89_max',\n 'R_8_max',\n 'D_88_mean',\n 'S_20_max',\n 'R_19_mean',\n 'D_88_max',\n 'R_4_max',\n 'D_137_max',\n 'D_126_count',\n 'D_63_count',\n 'D_137_last',\n 'D_64_count',\n 'D_66_count',\n 'D_68_count',\n 'S_6_max',\n 'D_117_count',\n 'D_139_max',\n 'D_120_count',\n 'D_143_max',\n 'D_81_last',\n 'B_38_count',\n 'D_116_count',\n 'D_140_max',\n 'D_143_last',\n 'D_109_last',\n 'D_93_max',\n 'D_93_mean',\n 'D_92_max',\n 'R_23_last',\n 'R_23_max',\n 'R_22_max',\n 'B_33_max',\n 'R_24_max',\n 'D_109_max',\n 'D_111_last',\n 'D_108_last',\n 'D_103_last',\n 'D_103_max',\n 'D_96_max',\n 'R_25_max',\n 'R_21_last',\n 'R_21_max',\n 'R_17_max',\n 'D_87_last',\n 'D_87_max',\n 'D_87_mean',\n 'S_18_max',\n 'R_17_last',\n 'B_42_mean',\n 'D_123_last',\n 'B_32_max',\n 'R_19_last',\n 'R_19_max',\n 'B_31_max',\n 'D_129_max'], inplace=True, axis=1)\n    del test_num_agg, test_cat_agg\n    print('shape after engineering', df.shape )\n    \n    return df\n\ntrain = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:57:16.103412Z","iopub.status.idle":"2022-07-30T17:57:16.105565Z","shell.execute_reply.started":"2022-07-30T17:57:16.105316Z","shell.execute_reply":"2022-07-30T17:57:16.105341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADD TARGETS\ntargets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain.target = train.target.astype('int8')\ndel targets\n\n# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\ntrain = train.sort_index().reset_index()\n\n# FEATURES\nFEATURES = train.columns[1:-1]\nprint(f'There are {len(FEATURES)} features!')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:57:16.108256Z","iopub.status.idle":"2022-07-30T17:57:16.108914Z","shell.execute_reply.started":"2022-07-30T17:57:16.108667Z","shell.execute_reply":"2022-07-30T17:57:16.108691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train XGB\nWe will train using `DeviceQuantileDMatrix`. This has a very small GPU memory footprint.","metadata":{}},{"cell_type":"code","source":"# LOAD XGB LIBRARY\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nprint('XGB Version',xgb.__version__)\n\n# XGB MODEL PARAMETERS\nxgb_parms = { \n    'max_depth':4, \n    'learning_rate':0.05, \n    'subsample':0.8,\n    'colsample_bytree':0.6, \n    'eval_metric':'logloss',\n    'objective':'binary:logistic',\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'random_state':SEED\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:46:11.868165Z","iopub.execute_input":"2022-07-16T16:46:11.868556Z","iopub.status.idle":"2022-07-16T16:46:11.958200Z","shell.execute_reply.started":"2022-07-16T16:46:11.868518Z","shell.execute_reply":"2022-07-16T16:46:11.957360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NEEDED WITH DeviceQuantileDMatrix BELOW\nclass IterLoadForDMatrix(xgb.core.DataIter):\n    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n        self.features = features\n        self.target = target\n        self.df = df\n        self.it = 0 # set iterator to 0\n        self.batch_size = batch_size\n        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n        super().__init__()\n\n    def reset(self):\n        '''Reset the iterator'''\n        self.it = 0\n\n    def next(self, input_data):\n        '''Yield next batch of data.'''\n        if self.it == self.batches:\n            return 0 # Return 0 when there's no more batch.\n        \n        a = self.it * self.batch_size\n        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n        dt = cudf.DataFrame(self.df.iloc[a:b])\n        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n        self.it += 1\n        return 1","metadata":{"execution":{"iopub.status.busy":"2022-07-16T16:46:11.959368Z","iopub.execute_input":"2022-07-16T16:46:11.959914Z","iopub.status.idle":"2022-07-16T16:46:11.972450Z","shell.execute_reply.started":"2022-07-16T16:46:11.959875Z","shell.execute_reply":"2022-07-16T16:46:11.971631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/kyakovlev\n# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\ndef amex_metric_mod(y_true, y_pred):\n\n    labels     = np.transpose(np.array([y_true, y_pred]))\n    labels     = labels[labels[:, 1].argsort()[::-1]]\n    weights    = np.where(labels[:,0]==0, 20, 1)\n    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n\n    gini = [0,0]\n    for i in [1,0]:\n        labels         = np.transpose(np.array([y_true, y_pred]))\n        labels         = labels[labels[:, i].argsort()[::-1]]\n        weight         = np.where(labels[:,0]==0, 20, 1)\n        weight_random  = np.cumsum(weight / np.sum(weight))\n        total_pos      = np.sum(labels[:, 0] *  weight)\n        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n        lorentz        = cum_pos_found / total_pos\n        gini[i]        = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1]/gini[0] + top_four)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:28:24.969379Z","iopub.execute_input":"2022-07-16T14:28:24.970113Z","iopub.status.idle":"2022-07-16T14:28:24.982004Z","shell.execute_reply.started":"2022-07-16T14:28:24.970076Z","shell.execute_reply":"2022-07-16T14:28:24.981105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = []\noof = []\ntrain = train.to_pandas() # free GPU memory\nTRAIN_SUBSAMPLE = 1.0\ngc.collect()\n\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    \n    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n    if TRAIN_SUBSAMPLE<1.0:\n        np.random.seed(SEED)\n        train_idx = np.random.choice(train_idx, \n                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n        np.random.seed(None)\n    \n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    \n    # TRAIN, VALID, TEST FOR FOLD K\n    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n    X_valid = train.loc[valid_idx, FEATURES]\n    y_valid = train.loc[valid_idx, 'target']\n    \n    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n    \n    # TRAIN MODEL FOLD K\n    model = xgb.train(xgb_parms, \n                dtrain=dtrain,\n                evals=[(dtrain,'train'),(dvalid,'valid')],\n                num_boost_round=9999,\n                early_stopping_rounds=100,\n                verbose_eval=100) \n    model.save_model(f'XGB_v{VER}_fold{fold}.xgb')\n    \n    # GET FEATURE IMPORTANCE FOR FOLD K\n    dd = model.get_score(importance_type='weight')\n    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n    importances.append(df)\n            \n    # INFER OOF FOLD K\n    oof_preds = model.predict(dvalid)\n    acc = amex_metric_mod(y_valid.values, oof_preds)\n    print('Kaggle Metric =',acc,'\\n')\n    \n    # SAVE OOF\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = oof_preds\n    oof.append( df )\n    \n    del dtrain, Xy_train, dd, df\n    del X_valid, y_valid, dvalid, model\n    _ = gc.collect()\n    \nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\nprint('OVERALL CV Kaggle Metric =',acc)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-16T14:28:24.983483Z","iopub.execute_input":"2022-07-16T14:28:24.983870Z","iopub.status.idle":"2022-07-16T14:34:58.855545Z","shell.execute_reply.started":"2022-07-16T14:28:24.983837Z","shell.execute_reply":"2022-07-16T14:34:58.854701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CLEAN RAM\ndel train\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:34:58.857827Z","iopub.execute_input":"2022-07-16T14:34:58.859890Z","iopub.status.idle":"2022-07-16T14:34:59.030094Z","shell.execute_reply.started":"2022-07-16T14:34:58.859857Z","shell.execute_reply":"2022-07-16T14:34:59.029312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save OOF Preds","metadata":{}},{"cell_type":"code","source":"oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\noof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\noof_xgb = oof_xgb.set_index('customer_ID_hash')\noof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\noof_xgb = oof_xgb.sort_index().reset_index(drop=True)\noof_xgb.to_csv(f'oof_xgb_v{VER}.csv',index=False)\noof_xgb.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:34:59.031322Z","iopub.execute_input":"2022-07-16T14:34:59.031672Z","iopub.status.idle":"2022-07-16T14:35:03.592195Z","shell.execute_reply.started":"2022-07-16T14:34:59.031639Z","shell.execute_reply":"2022-07-16T14:35:03.591432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOT OOF PREDICTIONS\nplt.hist(oof_xgb.oof_pred.values, bins=100)\nplt.title('OOF Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:35:03.593270Z","iopub.execute_input":"2022-07-16T14:35:03.593640Z","iopub.status.idle":"2022-07-16T14:35:03.909994Z","shell.execute_reply.started":"2022-07-16T14:35:03.593611Z","shell.execute_reply":"2022-07-16T14:35:03.909202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CLEAR VRAM, RAM FOR INFERENCE BELOW\ndel oof_xgb, oof\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:35:03.911065Z","iopub.execute_input":"2022-07-16T14:35:03.911858Z","iopub.status.idle":"2022-07-16T14:35:04.046373Z","shell.execute_reply.started":"2022-07-16T14:35:03.911816Z","shell.execute_reply":"2022-07-16T14:35:04.045588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf = importances[0].copy()\nfor k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\ndf['importance'] = df.iloc[:,1:].mean(axis=1)\ndf = df.sort_values('importance',ascending=False)\ndf.to_csv(f'xgb_feature_importance_v{VER}.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:35:04.047991Z","iopub.execute_input":"2022-07-16T14:35:04.048890Z","iopub.status.idle":"2022-07-16T14:35:04.082194Z","shell.execute_reply.started":"2022-07-16T14:35:04.048851Z","shell.execute_reply":"2022-07-16T14:35:04.081481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_FEATURES = 20\nplt.figure(figsize=(10,5*NUM_FEATURES//10))\nplt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES])\nplt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\nplt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T14:35:04.084772Z","iopub.execute_input":"2022-07-16T14:35:04.085019Z","iopub.status.idle":"2022-07-16T14:35:04.335986Z","shell.execute_reply.started":"2022-07-16T14:35:04.084996Z","shell.execute_reply":"2022-07-16T14:35:04.335258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process and Feature Engineer Test Data\nWe will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][1] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n\n[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n[5]: https://rapids.ai/","metadata":{}},{"cell_type":"code","source":"# CALCULATE SIZE OF EACH SEPARATE TEST PART\ndef get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n    chunk = len(customers)//NUM_PARTS\n    if verbose != '':\n        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n        print(f'There will be {chunk} customers in each part (except the last part).')\n        print('Below are number of rows in each part:')\n    rows = []\n\n    for k in range(NUM_PARTS):\n        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n        else: cc = customers[k*chunk:(k+1)*chunk]\n        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n        rows.append(s)\n    if verbose != '': print( rows )\n    return rows,chunk\n\n# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\nNUM_PARTS = 4\nTEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n\nprint(f'Reading test data...')\ntest = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\ncustomers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\nrows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T23:25:31.064246Z","iopub.execute_input":"2022-06-01T23:25:31.064756Z","iopub.status.idle":"2022-06-01T23:25:33.699775Z","shell.execute_reply.started":"2022-06-01T23:25:31.064719Z","shell.execute_reply":"2022-06-01T23:25:33.698995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test","metadata":{}},{"cell_type":"code","source":"# INFER TEST DATA IN PARTS\nskip_rows = 0\nskip_cust = 0\ntest_preds = []\n\nfor k in range(NUM_PARTS):\n    \n    # READ PART OF TEST DATA\n    print(f'\\nReading test data...')\n    test = read_file(path = TEST_PATH)\n    test = test.iloc[skip_rows:skip_rows+rows[k]]\n    skip_rows += rows[k]\n    print(f'=> Test part {k+1} has shape', test.shape )\n    \n    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n    test = process_and_feature_engineer(test)\n    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n    skip_cust += num_cust\n    \n    # TEST DATA FOR XGB\n    X_test = test[FEATURES]\n    dtest = xgb.DMatrix(data=X_test)\n    test = test[['P_2_mean']] # reduce memory\n    del X_test\n    gc.collect()\n\n    # INFER XGB MODELS ON TEST DATA\n    model = xgb.Booster()\n    model.load_model(f'XGB_v{VER}_fold0.xgb')\n    preds = model.predict(dtest)\n    for f in range(1,FOLDS):\n#         11) \n        if f==3:\n            continue\n        model.load_model(f'XGB_v{VER}_fold{f}.xgb')\n        preds += model.predict(dtest)\n    preds /= (FOLDS-1)\n    test_preds.append(preds)\n\n    # CLEAN MEMORY\n    del dtest, model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T23:25:33.701085Z","iopub.execute_input":"2022-06-01T23:25:33.701423Z","iopub.status.idle":"2022-06-01T23:26:38.059268Z","shell.execute_reply.started":"2022-06-01T23:25:33.701396Z","shell.execute_reply":"2022-06-01T23:26:38.058458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission CSV","metadata":{}},{"cell_type":"code","source":"# WRITE SUBMISSION FILE\ntest_preds = np.concatenate(test_preds)\ntest = cudf.DataFrame(index=customers,data={'prediction':test_preds})\nsub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\nsub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\nsub = sub.set_index('customer_ID_hash')\nsub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\nsub = sub.reset_index(drop=True)\n\n# DISPLAY PREDICTIONS\nsub.to_csv(f'submission_xgb_v{VER}.csv',index=False)\nprint('Submission file shape is', sub.shape )\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T23:26:38.060995Z","iopub.execute_input":"2022-06-01T23:26:38.061347Z","iopub.status.idle":"2022-06-01T23:26:39.073254Z","shell.execute_reply.started":"2022-06-01T23:26:38.061312Z","shell.execute_reply":"2022-06-01T23:26:39.072485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOT PREDICTIONS\nplt.hist(sub.to_pandas().prediction, bins=100)\nplt.title('Test Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T23:26:39.074437Z","iopub.execute_input":"2022-06-01T23:26:39.074873Z","iopub.status.idle":"2022-06-01T23:26:39.799231Z","shell.execute_reply.started":"2022-06-01T23:26:39.074837Z","shell.execute_reply":"2022-06-01T23:26:39.798463Z"},"trusted":true},"execution_count":null,"outputs":[]}]}